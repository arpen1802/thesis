{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60b26f1d-25a8-49ef-a783-280739878a17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture setup_output\n",
    "%run 'setup.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd8127bd-5d24-4f11-8c26-e68d88c9c5db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pdb\n",
    "import seaborn as sns\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.data_processing import load_and_process_data\n",
    "from src.EVChargingModel import EVDataset\n",
    "from src.dnn_model import EVChargingModel\n",
    "from src.FullyConnected import FullyConnected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b90279-81e3-4d7c-81ac-4d2554f1d480",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define dataset file path\n",
    "file_path = '../results/removed_outliers.parquet'\n",
    "df = pd.read_parquet(file_path)\n",
    "\n",
    "# Define features and target variables\n",
    "# removed 'c_chargingmethod','c_chargingtype' 'mean_dep_time','latitude', 'longitude',  'start_datetime'\n",
    "relevant_features = ['c_vin', 'c_realstartsoc', 'weekday_numerical', 'is_weekend',\n",
    "                     'mean_consumption', 'mean_duration', 'latitude', 'longitude',\n",
    "                     'start_hour', 'start_day', 'is_home_spot', 'is_location_one',\n",
    "                     'start_datetime', 'delta_soc_real', 'plugin_duration_hr']\n",
    "\n",
    "target = 'plugin_duration_hr' #, 'delta_soc_real', plugin_duration_hr\n",
    "\n",
    "df = df[relevant_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4305ef2b-7148-4e01-be90-8cb47bc1ca92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training batch size\n",
    "batch_size = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09011bbc-82d7-4ba7-b296-15a9100d68fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(df))\n",
    "df = df.dropna()\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d97cb6-1a24-48a6-ac66-a4c43591e932",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sort the DataFrame by 'c_vin' and 'start_datetime'\n",
    "df = df.sort_values(by=['c_vin', 'start_datetime'])\n",
    "# Add new features for previous session plugin_duration_hr and delta_soc_real\n",
    "df['prev_plugin_duration_hr'] = df.groupby('c_vin')['plugin_duration_hr'].shift(1)\n",
    "df['prev_delta_soc_real'] = df.groupby('c_vin')['delta_soc_real'].shift(1)\n",
    "\n",
    "df['prev_plugin_duration_hr'] = df['prev_plugin_duration_hr'].fillna(df['plugin_duration_hr'])\n",
    "df['prev_delta_soc_real'] = df['prev_delta_soc_real'].fillna(df['delta_soc_real'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc3bddc-3851-4a07-95c1-846e64d2bd7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df['c_vin_encoded'] = label_encoder.fit_transform(df['c_vin'])\n",
    "df = df.drop(columns=['c_vin'])\n",
    "\n",
    "features = ['c_vin_encoded', 'c_realstartsoc', 'weekday_numerical', 'is_weekend',\n",
    "            'mean_consumption', 'mean_duration', 'latitude', 'longitude',\n",
    "            'start_hour', 'start_day', 'is_home_spot', 'is_location_one',\n",
    "            'prev_plugin_duration_hr', 'prev_delta_soc_real']\n",
    "\n",
    "\n",
    "feature_scaler = StandardScaler()\n",
    "target_scaler = StandardScaler()\n",
    "\n",
    "df[features] = feature_scaler.fit_transform(df[features])\n",
    "df[[target]] = target_scaler.fit_transform(df[[target]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9eb65e8a-9b2a-4a6e-b478-a85546b8638a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df[features]\n",
    "y = df[[target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57283fc2-bea2-4f84-b63b-fe9538acd481",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b992b6c-eae1-47d7-9294-6993493ec1b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6905208 863151 863152\n",
      "6905208 863151 863152\n"
     ]
    }
   ],
   "source": [
    "# Make sure the dimensions are the same for different sets\n",
    "print(f\"X_train: {len(X_train)}, X_val: {len(X_val)}, X_test: {len(X_test)}\")\n",
    "print(f\"y_train: {len(y_train)}, y_val: {len(y_val)}, y_test: {len(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f49d679-3c28-4dfc-a7ef-e56b8618d7f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_val = np.array(X_val)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "\n",
    "# Convert the data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "767c0bf7-0afd-4fc4-b593-ac0c0c6af543",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create datasets and dataloaders\n",
    "train_dataset = EVDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = EVDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = EVDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d90fef79-d2ab-4936-bc30-cb0c8e95ee57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up logger\n",
    "csv_logger = CSVLogger(\"logs\", name=\"dnn-soc\")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath='checkpoints',\n",
    "    filename='best_checkpoint',\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ba88a3e-a3d6-4df3-a67a-08fb55a903b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "model = FullyConnected(input_size=X_train.shape[1], dropout_prob=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf74bed3-4f27-4558-9219-95cb8c785082",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/ec2-user/SageMaker/Q658166-thesis/checkpoints exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fabfdbadc8d7499a9f29cfc73826f02a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f322f1d1690>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=50,\n",
    "                     logger=csv_logger,\n",
    "                     callbacks=[checkpoint_callback])\n",
    "\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6a1ff15-4232-4bcd-aa00-158ce5124d40",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# checkpoint_path = 'checkpoints/best_checkpoint-v71.ckpt'\n",
    "# model = FullyConnected.load_from_checkpoint(checkpoint_path, input_size=X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "176ef54d-72e1-436c-a6e3-d6dd478af971",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60aca27b-9ea9-427f-9fd7-9505b1a91232",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error(MAE): 0.4965437650680542\n",
      "Mean Squared Error(MAE): 0.6786376237869263\n",
      "Mean Absolute Error(MAE) original: 11.006671243734607\n",
      "Mean Squared Error(MAE) original: 15.043069770238704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mae = mean_absolute_error(y_test_tensor.to('cpu'), y_pred.to('cpu'))\n",
    "rmse = mean_squared_error(y_test_tensor.to('cpu'), y_pred.to('cpu'), squared=False)\n",
    "print(f\"Mean Absolute Error(MAE): {mae}\")\n",
    "print(f\"Mean Squared Error(MAE): {rmse}\")\n",
    "\n",
    "y_pred_original = target_scaler.inverse_transform(y_pred.to('cpu'))\n",
    "y_test_original = target_scaler.inverse_transform(y_test_tensor.to('cpu'))\n",
    "\n",
    "mae_original = mean_absolute_error(y_pred_original, y_test_original)\n",
    "rmse_original = mean_squared_error(y_pred_original, y_test_original, squared=False)\n",
    "print(f\"Mean Absolute Error(MAE) original: {mae_original}\")\n",
    "print(f\"Mean Squared Error(MAE) original: {rmse_original}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
